# Robot Vision Controller with AI Navigation & Nav2 Integration

H·ªá th·ªëng ƒëi·ªÅu khi·ªÉn robot TurtleBot3 t·ª± ƒë·ªông v·ªõi AI Agent th√¥ng minh, t√≠ch h·ª£p **Nav2 navigation stack** cho path planning an to√†n. Robot c√≥ th·ªÉ hi·ªÉu v√† th·ª±c hi·ªán nhi·ªám v·ª• ph·ª©c t·∫°p t·ª´ natural language prompts nh∆∞ ƒë·∫øm v·∫≠t th·ªÉ, b√°m theo m·ª•c ti√™u di ƒë·ªông, tu·∫ßn tra v√≤ng tr√≤n, v√† nhi·ªÅu h∆°n n·ªØa.

## ü§ñ AI Models Used

|         Model           |                     Purpose                        |        When Used        | Critical |
|-------------------------|----------------------------------------------------|-------------------------|----------|
| **LLM (Llama 3.1 70B)** | Parse natural language prompt ‚Üí structured mission |       1x at startup     |  ‚úÖ Yes  |
|    **YOLO (v11n)**      |            Object detection & tracking             | Continuous (2Hz cached) |  ‚úÖ Yes  |

**Performance:**
- üöÄ Real-time navigation: <100ms per iteration
- üíæ Memory usage: ~0.5GB (YOLO only)
- ‚ö° Startup time: ~1 second

---

## üìã M·ª•c l·ª•c
- [C·∫•u tr√∫c th∆∞ m·ª•c](#c·∫•u-tr√∫c-th∆∞-m·ª•c)
- [T·ªïng quan h·ªá th·ªëng](#t·ªïng-quan-h·ªá-th·ªëng)
- [Ki·∫øn tr√∫c](#ki·∫øn-tr√∫c)
- [Nav2 Integration](#nav2-integration)
- [Mission Types](#mission-types)
- [Y√™u c·∫ßu h·ªá th·ªëng](#y√™u-c·∫ßu-h·ªá-th·ªëng)
- [C√†i ƒë·∫∑t](#c√†i-ƒë·∫∑t)
- [C√°ch ch·∫°y](#c√°ch-ch·∫°y)
- [Ghi ch√∫ quan tr·ªçng](#ghi-ch√∫-quan-tr·ªçng)

## üìÅ C·∫•u tr√∫c th∆∞ m·ª•c

```
multi_function_agent/
    ‚îú‚îÄ‚îÄ configs/
    ‚îÇ   ‚îî‚îÄ‚îÄ config.yml                            # C·∫•u h√¨nh system + Nav2
    ‚îî‚îÄ‚îÄ robot_vision_controller/
        ‚îú‚îÄ‚îÄ main.py                               # Entry point - HYBRID LOOP
        ‚îú‚îÄ‚îÄ core/
        ‚îÇ   ‚îú‚îÄ‚îÄ query_extractor.py                # Prompt information extraction
        ‚îÇ   ‚îú‚îÄ‚îÄ goal_parser.py                    # LLM mission parser 
        ‚îÇ   ‚îú‚îÄ‚îÄ mission_controller.py             # Mission state machine 
        ‚îÇ   ‚îî‚îÄ‚îÄ models.py                         # YOLO model management
        ‚îú‚îÄ‚îÄ navigation/
        ‚îÇ   ‚îú‚îÄ‚îÄ nav2_interface.py                 # Nav2 Python interface
        ‚îÇ   ‚îú‚îÄ‚îÄ navigation_reasoner.py            # Mission-aware manual control
        ‚îÇ   ‚îî‚îÄ‚îÄ robot_controller_interface.py     # ROS/Gazebo interface + Nav2
        ‚îú‚îÄ‚îÄ perception/
        ‚îÇ   ‚îú‚îÄ‚îÄ lidar_monitor.py                  # Real-time collision avoidance
        ‚îÇ   ‚îú‚îÄ‚îÄ robot_vision_analyzer.py          # YOLO + LIDAR spatial analysis
        ‚îÇ   ‚îú‚îÄ‚îÄ spatial_detector.py               # LIDAR spatial analysis
        ‚îÇ   ‚îî‚îÄ‚îÄ rtsp_stream_handler.py            # RTSP stream handler        
        ‚îî‚îÄ‚îÄ utils/
            ‚îú‚îÄ‚îÄ geometry_utils.py                 # Geometry calculation
            ‚îú‚îÄ‚îÄ movement_commands.py              # Commands to move
            ‚îú‚îÄ‚îÄ safety_checks.py                  # Safety First
            ‚îú‚îÄ‚îÄ ros_interface.py                  # ROS utilities
            ‚îî‚îÄ‚îÄ log/
                ‚îú‚îÄ‚îÄ error_handlers.py             # Error logging
                ‚îú‚îÄ‚îÄ output_formatter.py           # Output logging
                ‚îî‚îÄ‚îÄ performance_logger.py         # Performance logging

ros2_bridge_service/
‚îî‚îÄ‚îÄ robot_bridge_server.py                        # HTTP ‚Üî ROS2 bridge

turtlebot3_ws/
‚îî‚îÄ‚îÄ src/
    ‚îî‚îÄ‚îÄ custom_controller/
        ‚îî‚îÄ‚îÄ custom_controller/
            ‚îî‚îÄ‚îÄ rtsp_publisher.py                 # RTSP stream publisher
```

---

## üéØ T·ªïng quan h·ªá th·ªëng

H·ªá th·ªëng bao g·ªìm 5 th√†nh ph·∫ßn ch√≠nh:

1. **TurtleBot3 Simulation (Gazebo)**: Robot ·∫£o v·ªõi camera, lidar, odometry
2. **RTSP Streaming Pipeline**: Truy·ªÅn video t·ª´ robot qua RTSP protocol
3. **Nav2 Stack**: Global path planning + local obstacle avoidance
4. **AI Agent**: LLM prompt parsing + YOLO object detection
5. **LIDAR Safety Layer**: Real-time collision prevention v·ªõi veto capability

### Workflow t·ªïng quan - Hybrid Navigation
```
User Prompt ‚Üí LLM Parser (1x) ‚Üí Mission Controller
                                       ‚Üì
                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                         ‚îÇ  MISSION STATE MACHINE  ‚îÇ
                         ‚îÇ  ‚Ä¢ Track progress       ‚îÇ
                         ‚îÇ  ‚Ä¢ Generate directives  ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                     ‚Üì
                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                         ‚îÇ  VISION ANALYSIS        ‚îÇ
                         ‚îÇ  ‚Ä¢ YOLO: Object detect  ‚îÇ
                         ‚îÇ  ‚Ä¢ LIDAR: Spatial map   ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                     ‚Üì
                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                         ‚îÇ  NAVIGATION DECISION    ‚îÇ
                         ‚îÇ  ‚Ä¢ Nav2 or Manual?      ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                     ‚Üì
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚ñº Nav2 Path                    Manual Path  ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  NAV2 EXECUTION  ‚îÇ                          ‚îÇ MANUAL EXECUTION ‚îÇ
    ‚îÇ  ‚Ä¢ Path planning ‚îÇ                          ‚îÇ ‚Ä¢ Direct control ‚îÇ
    ‚îÇ  ‚Ä¢ Obstacle avoid‚îÇ                          ‚îÇ ‚Ä¢ LIDAR safety   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚Üì
                         Robot executes safely
```

---

## üèóÔ∏è Ki·∫øn tr√∫c

### AI Pipeline (Optimized)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  STARTUP PHASE (1 second)                                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  1. Load YOLO model (0.1s)                               ‚îÇ
‚îÇ  2. User prompt ‚Üí LLM parse (3s)                         ‚îÇ
‚îÇ  3. Initialize Nav2 + ROS2 (1s)                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  MAIN LOOP (10 Hz - 100ms per iteration)                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                          ‚îÇ
‚îÇ  Priority 0: LIDAR Safety Check (10ms)                   ‚îÇ
‚îÇ  ‚îú‚îÄ Min distance check                                   ‚îÇ
‚îÇ  ‚îî‚îÄ Veto Nav2/Manual if critical                         ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Priority 1: Vision Analysis (50ms, cached 0.5s)         ‚îÇ
‚îÇ  ‚îú‚îÄ YOLO object detection (if mission needs)             ‚îÇ
‚îÇ  ‚îú‚îÄ LIDAR spatial analysis                               ‚îÇ
‚îÇ  ‚îî‚îÄ Target tracking (bbox center + distance)             ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Priority 2: Mission State Update (5ms)                  ‚îÇ
‚îÇ  ‚îú‚îÄ Count progress / Lap tracking                        ‚îÇ
‚îÇ  ‚îú‚îÄ Target visibility check                              ‚îÇ
‚îÇ  ‚îî‚îÄ Generate directive (explore/track/patrol)            ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Priority 3: Navigation Decision (5ms)                   ‚îÇ
‚îÇ  ‚îú‚îÄ Can use Nav2? ‚Üí Send goal (non-blocking)             ‚îÇ
‚îÇ  ‚îî‚îÄ Need manual? ‚Üí Generate cmd_vel                      ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Priority 4: Execute Command (20ms)                      ‚îÇ
‚îÇ  ‚îú‚îÄ Publish to /cmd_vel or Nav2 action                   ‚îÇ
‚îÇ  ‚îî‚îÄ Monitor safety during execution                      ‚îÇ
‚îÇ                                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Component Diagram

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         GAZEBO SIMULATION (TurtleBot3)                      ‚îÇ
‚îÇ  ‚Ä¢ Camera: 640x480 @ 15fps                                  ‚îÇ
‚îÇ  ‚Ä¢ Lidar: 360¬∞ laser, 0.12-3.5m range                       ‚îÇ
‚îÇ  ‚Ä¢ Odometry: Position + velocity                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         RTSP STREAMING                                      ‚îÇ
‚îÇ  Camera ‚Üí rtsp_publisher ‚Üí MediaMTX ‚Üí rtsp://...            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         NAV2 STACK                                          ‚îÇ
‚îÇ  ‚Ä¢ SLAM: Real-time mapping                                  ‚îÇ
‚îÇ  ‚Ä¢ Costmap: Obstacle inflation                              ‚îÇ
‚îÇ  ‚Ä¢ Planners: A* global + DWA local                          ‚îÇ
‚îÇ  ‚Ä¢ Recovery: Rotate, backup behaviors                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         AI AGENT (YOLO + LIDAR)                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
‚îÇ  ‚îÇ YOLO Object Detection (50ms)              ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Person, bottle, cup, chair, etc.       ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Bbox, center, distance estimation      ‚îÇ              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
‚îÇ  ‚îÇ LIDAR Spatial Analysis (10ms)             ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Safety score calculation               ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Clear path detection                   ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Obstacle distance mapping              ‚îÇ              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
‚îÇ  ‚îÇ Navigation Reasoner (5ms)                 ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Mission directive execution            ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Hybrid Nav2/Manual selection           ‚îÇ              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         ROS2 INTERFACE                                      ‚îÇ
‚îÇ  ‚Ä¢ /cmd_vel: Direct velocity control                        ‚îÇ
‚îÇ  ‚Ä¢ /navigate_to_pose: Nav2 goals                            ‚îÇ
‚îÇ  ‚Ä¢ /scan: LIDAR input                                       ‚îÇ
‚îÇ  ‚Ä¢ /odom: Position feedback                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üó∫Ô∏è Nav2 Integration

### **L·ª£i √≠ch c·ªßa Nav2**

#### **1. Proactive Navigation**
- **Tr∆∞·ªõc (Reactive LIDAR):** Robot ch·ªâ ph·∫£n ·ª©ng khi g·∫ßn v·∫≠t c·∫£n
- **Sau (Nav2):** Robot bi·∫øt map, plan ƒë∆∞·ªùng tr∆∞·ªõc, tr√°nh ch∆∞·ªõng ng·∫°i v·∫≠t s·ªõm

#### **2. Global Path Planning**
- Dijkstra/A* algorithm tr√™n map
- T√¨m ƒë∆∞·ªùng t·ªëi ∆∞u t·ª´ A ‚Üí B
- Tr√°nh v√πng nguy hi·ªÉm tr√™n costmap

#### **3. Local Obstacle Avoidance**
- DWA (Dynamic Window Approach)
- Real-time trajectory adjustment
- Tr√°nh ch∆∞·ªõng ng·∫°i v·∫≠t ƒë·ªông

#### **4. Recovery Behaviors**
- T·ª± ƒë·ªông tho√°t khi b·ªã stuck
- Rotate ‚Üí Clear costmap ‚Üí Retry
- Backup v√† t√¨m ƒë∆∞·ªùng kh√°c

#### **5. Code Reduction**
- Simplified vision pipeline (YOLO + LIDAR only)
- Nav2 handles complex path planning
- Focus on mission-specific behaviors

### **Khi n√†o d√πng Nav2 vs Manual**

|      Directive      | Nav2 | Manual |             L√Ω do            |
|---------------------|------|--------|------------------------------|
| `explore_random`    |  ‚úÖ  |        |       Random goals on map    |
| `patrol_circle`     |  ‚úÖ  |        |  Arc navigation with goals   |
| `track_follow`      |  ‚ö†Ô∏è  |   ‚úÖ   | Target di ƒë·ªông, c·∫ßn reactive |
| `track_backup`      |      |   ‚úÖ   |   Precise distance control   |
| `track_search_spin` |      |   ‚úÖ   |     360¬∞ rotation in place   |
| `track_approach`    |  ‚úÖ  |        |     Goal-based approach      |

---

## üéÆ Mission Types

Robot h·ªó tr·ª£ 3 lo·∫°i nhi·ªám v·ª• th√¥ng qua natural language:

### 0. **Count Objects** (ƒê·∫øm v·∫≠t th·ªÉ)
```bash
"ƒê·∫øm 10 chai n∆∞·ªõc"
"Count 5 cups"
"T√¨m 3 ng∆∞·ªùi"
```
**Navigation:** Nav2 exploration + YOLO detection  
**Behavior:** Explore v√† ƒë·∫øm objects, d·ª´ng khi ƒë·ªß s·ªë l∆∞·ª£ng

### 1. **Follow Target** (B√°m theo m·ª•c ti√™u)
```bash
"Theo sau ng∆∞·ªùi ƒëang ƒëi"
"Follow the person"
"ƒêi theo m·ª•c ti√™u di ƒë·ªông"
```
**Navigation:** Hybrid (Nav2 approach + manual tracking)  
**Behavior:** 
- Track target at safe distance (1.0-2.5m)
- YOLO bbox tracking v·ªõi real-time adjustment
- Search pattern if lost >3s

### 2. **Patrol Laps** (Tu·∫ßn tra v√≤ng)
```bash
"ƒêi 20 v√≤ng tr√≤n"
"Patrol 5 laps"
"Tu·∫ßn tra 10 v√≤ng"
```
**Navigation:** Nav2 arc goals  
**Behavior:** Complete N circular laps, return to start position

### 3. **Explore Area** (Kh√°m ph√°)
```bash
"Kh√°m ph√° t·ª± do"
"Explore the environment"
"Run wide automatically in 60 seconds"
```
**Navigation:** Nav2 random goals  
**Behavior:** Random waypoint generation on map, smooth navigation

---

## üíª Y√™u c·∫ßu h·ªá th·ªëng

### Ph·∫ßn m·ªÅm
- **Ubuntu 22.04 LTS** (khuy·∫øn ngh·ªã)
- **ROS2 Humble** 
- **Python 3.10+**
- **Gazebo 11**

### Th∆∞ vi·ªán Python ch√≠nh
- `ultralytics` (YOLOv11n) - Object detection
- `opencv-python` - Image processing
- `flask` - ROS2 bridge server
- `numpy` - Math operations
- `pyyaml` - Config parsing
- `torch` - YOLO backend
- `transforms3d` - Nav2 quaternion conversion

### ROS2 Packages
- `ros-humble-turtlebot3*`
- `ros-humble-navigation2`
- `ros-humble-slam-toolbox`
- `ros-humble-nav2-bringup`

### Tools
- **MediaMTX**: RTSP streaming server
- **FFmpeg**: Video encoding/decoding
- **gnome-terminal**: Script automation

### Ph·∫ßn c·ª©ng khuy·∫øn ngh·ªã
- **RAM**: 8GB+ (YOLO + Nav2)
- **GPU**: Optional (YOLO faster with CUDA)
- **CPU**: 4+ cores

**Performance Notes:**
- CPU-only: ~50ms YOLO inference
- With GPU: ~20ms YOLO inference
- Memory: 0.5GB (YOLO) + 1GB (Nav2) = ~2GB total

---

## üîß C√†i ƒë·∫∑t

### 1. C√†i ƒë·∫∑t ROS2 v√† TurtleBot3

```bash
# C√†i ROS2 Humble
# Follow: https://docs.ros.org/en/humble/Installation.html

# C√†i TurtleBot3 packages
sudo apt install ros-humble-turtlebot3*

# C√†i Nav2 packages
sudo apt install ros-humble-navigation2 ros-humble-nav2-bringup

# C√†i SLAM Toolbox
sudo apt install ros-humble-slam-toolbox

# Set TurtleBot3 model
echo "export TURTLEBOT3_MODEL=waffle" >> ~/.bashrc
source ~/.bashrc
```

### 2. Setup Workspace ROS2

```bash
# T·∫°o workspace
mkdir -p ~/turtlebot3_ws/src
cd ~/turtlebot3_ws/src

# Clone custom controller (n·∫øu c√≥ repo)
# ho·∫∑c copy th∆∞ m·ª•c custom_controller v√†o ƒë√¢y

# Build workspace
cd ~/turtlebot3_ws
colcon build
source install/setup.bash
```

### 3. C√†i ƒë·∫∑t MediaMTX

```bash
cd ~
# Download t·ª´: https://github.com/bluenviron/mediamtx/releases
wget https://github.com/bluenviron/mediamtx/releases/download/v1.8.0/mediamtx_v1.8.0_linux_amd64.tar.gz
tar -xzf mediamtx_v1.8.0_linux_amd64.tar.gz
chmod +x mediamtx
```

### 4. Setup ROS2 Bridge Service

```bash
cd ~
mkdir ros2_bridge_service
cd ros2_bridge_service

# T·∫°o virtual environment
python3 -m venv ros_env
source ros_env/bin/activate

# C√†i dependencies
pip install flask rclpy geometry-msgs
```

### 5. C√†i ƒë·∫∑t NEMO Agent Toolkit

```bash
cd ~
git clone <your-repo-url> nemo-agent-toolkit

cd nemo-agent-toolkit
python3 -m venv .venv
source .venv/bin/activate

# C√†i dependencies (YOLO only, no BLIP2)
pip install ultralytics opencv-python pyyaml numpy torch transforms3d
```

### 6. T·∫°o Map v·ªõi SLAM

```bash
# Terminal 1: Launch Gazebo
ros2 launch turtlebot3_gazebo turtlebot3_world.launch.py

# Terminal 2: Launch SLAM
ros2 launch slam_toolbox online_async_launch.py use_sim_time:=True

# Terminal 3: Launch RViz
rviz2

# Terminal 4: Teleop ƒë·ªÉ kh√°m ph√° (t·∫°o map)
ros2 run turtlebot3_teleop teleop_keyboard

# Sau khi map ƒë·ªß, save map (Terminal 5)
cd ~
ros2 run nav2_map_server map_saver_cli -f turtlebot3_nav2_map
```

### 7. Copy Project Files

```bash
# Copy multi_function_agent v√†o nemo-agent-toolkit
cp -r multi_function_agent ~/nemo-agent-toolkit/examples/

# Copy robot_bridge_server.py
cp robot_bridge_server.py ~/ros2_bridge_service/

# Copy rtsp_publisher.py
cp rtsp_publisher.py ~/turtlebot3_ws/src/custom_controller/custom_controller/
```

---

## üöÄ C√°ch ch·∫°y

### B∆∞·ªõc 1: Kh·ªüi ƒë·ªông Robot + Nav2 Stack

T·∫°o script `start_robot_nav2.sh`:

```bash
#!/bin/bash
run_in_terminal() {
    gnome-terminal -- bash -c "$1; exec bash"
}

echo "Starting robot + Nav2 stack..."

# Start Gazebo
run_in_terminal "cd ~ && ros2 launch turtlebot3_gazebo turtlebot3_world.launch.py"
sleep 5

# Start Nav2 with saved map
run_in_terminal "cd ~ && ros2 launch turtlebot3_navigation2 navigation2.launch.py use_sim_time:=True map:=$HOME/turtlebot3_nav2_map.yaml"
sleep 3

# Start MediaMTX
run_in_terminal "cd ~ && ./mediamtx"
sleep 2  

# Start RTSP publisher
run_in_terminal "cd ~/turtlebot3_ws && source install/setup.bash && cd src/custom_controller/custom_controller && python3 rtsp_publisher.py"
sleep 2

# Start bridge server
run_in_terminal "cd ~/ros2_bridge_service && source ros_env/bin/activate && python robot_bridge_server.py"

echo "All services started!"
echo "In RViz: Set initial pose with '2D Pose Estimate' tool"
```

Ch·∫°y script:
```bash
chmod +x start_robot_nav2.sh
./start_robot_nav2.sh
```

**QUAN TR·ªåNG:** Trong RViz, d√πng "2D Pose Estimate" ƒë·ªÉ set v·ªã tr√≠ ban ƒë·∫ßu c·ªßa robot.

### B∆∞·ªõc 2: Ch·∫°y AI Agent v·ªõi Mission

```bash
cd ~/nemo-agent-toolkit
source .venv/bin/activate

# Example missions:

# Explore with Nav2
nat run --config_file examples/multi_function_agent/configs/config.yml --input "Run wide automatically in 60 seconds"

# Count objects (YOLO)
nat run --config_file examples/multi_function_agent/configs/config.yml --input "ƒê·∫øm 10 chai n∆∞·ªõc"

# Follow target (Hybrid Nav2 + YOLO)
nat run --config_file examples/multi_function_agent/configs/config.yml --input "Theo sau ng∆∞·ªùi ƒëang ƒëi"

# Patrol laps (Nav2)
nat run --config_file examples/multi_function_agent/configs/config.yml --input "ƒêi 5 v√≤ng tr√≤n"
```

---

## üìù Ghi ch√∫ quan tr·ªçng

### Hybrid Navigation Strategy

**Nav2 Usage (70-80% of time):**
- ‚úÖ `explore_random`: Random waypoints on the map
- ‚úÖ `patrol_*`: Arc-based circular motion
- ‚úÖ `track_approach`: Goal-based target approach
- ‚úÖ Smooth, collision-free paths
- ‚úÖ Auto recovery from stuck situations

**Manual Control (20-30% of time):**
- ‚úÖ `track_follow`: Real-time YOLO bbox tracking
- ‚úÖ `track_backup`: Precise reverse movements
- ‚úÖ `track_search_spin`: 360¬∞ search rotation
- ‚úÖ Nav2 fallback when goal rejected
- ‚úÖ Emergency behaviors

### Safety Features

**Multi-Level Protection:**
- üõ°Ô∏è **Level 0 (Nav2 Costmap)**: Proactive path planning around obstacles
- üõ°Ô∏è **Level 1 (DWA Local Planner)**: Real-time trajectory adjustment
- üõ°Ô∏è **Level 2 (LIDAR Veto)**: Pre-execution safety check
- üõ°Ô∏è **Level 3 (20Hz Monitor)**: Continuous safety during movement
- üõ°Ô∏è **Level 4 (Immediate Abort)**: <50ms stop at critical distance
- üõ°Ô∏è **Level 5 (Progressive Scale)**: Speed reduction near obstacles

**Safety Guarantees:**
- ‚ö° Response time: <50ms from detection to stop
- üéØ Abort accuracy: 100% (blocking execution)
- üìä Monitoring rate: 20Hz during movement
- üîí Override capability: LIDAR Safety > Nav2 > Manual

### AI Pipeline Features

- **LLM-Powered Parsing**: Natural language ‚Üí Structured missions (1x startup)
- **YOLO Detection**: 80 COCO classes, 50ms inference, 2Hz cached
- **State Machine**: Mission progress tracking
- **Completion Detection**: Auto-stop when goal achieved
- **Adaptive Navigation**: Hybrid Nav2/Manual based on directive
- **Real-time Tracking**: YOLO bbox center + distance estimation

### Performance Characteristics

| Metric | Value | Note |
|--------|-------|------|
| **Iteration rate** | 10 Hz | 100ms per loop |
| **YOLO inference** | 50ms | Cached 0.5s |
| **LIDAR processing** | 10ms | Every iteration |
| **Navigation decision** | 5ms | Rule-based |
| **Memory usage** | ~2GB | YOLO + Nav2 |
| **Startup time** | ~5s | Models + ROS2 |

### Limitations

**Technical Constraints:**
- **YOLO Classes**: Limited to 80 COCO classes
- **Distance Estimation**: Heuristic from bbox size + LIDAR
- **Lap Detection**: Simple odometry-based (no SLAM loop closure)
- **LLM Dependency**: Requires NIM API for prompt parsing
- **Single Robot**: No multi-robot coordination
- **Map Dependency**: Nav2 requires pre-built SLAM map

**Known Issues:**
- Camera resolution fixed at 640x480
- YOLO confidence threshold: 0.5 (adjustable)
- Nav2 goal tolerance: 0.2m position, 0.1rad orientation
- Bridge mode: No Nav2 support (requires native ROS2)